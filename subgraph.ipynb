{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTraversal:\n",
    "    def createGraph(self, sentences):\n",
    "        #DG=nx.DiGraph()\n",
    "        DG=nx.MultiDiGraph()\n",
    "        tokens = nltk.word_tokenize(sentences)\n",
    "        token_count = len(tokens)\n",
    "        for i in range(token_count):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            DG.add_edges_from([(tokens[i-1], tokens[i])], weight=1)\n",
    "        return DG\n",
    "\n",
    "\n",
    "    def getMCS0(self, G_source, G_new):\n",
    "        \"\"\"\n",
    "        Creator: Bonson\n",
    "        Return the MCS of the G_new graph that is present in the G_source graph\n",
    "        \"\"\"\n",
    "        order =  nx.topological_sort(G_new)\n",
    "        print(\"##### topological sort #####\")\n",
    "        print(order)\n",
    "\n",
    "        #objSubGraph = nx.DiGraph()\n",
    "        objSubGraph = nx.MultiDiGraph()\n",
    "        for i in range(len(order)-1):\n",
    "            if G_source.nodes().__contains__(order[i]) and G_source.nodes().__contains__(order[i+1]):\n",
    "                print(\"Contains Nodes {0} -> {1} \".format(order[i], order[i+1]))\n",
    "                objSubGraph.add_node(order[i])\n",
    "                objSubGraph.add_node(order[i+1])\n",
    "                objSubGraph.add_edge(order[i], order[i+1])\n",
    "            else:\n",
    "                print(\"Does Not Contains Nodes {0} -> {1} \".format(order[i], order[i+1]))\n",
    "                continue\n",
    "\n",
    "    def getMCS1(self, G_source, G_new):\n",
    "        matching_graph=nx.Graph()\n",
    "        #matching_graph=nx.MultiDiGraph()\n",
    "        for n1,n2,attr in G_new.edges(data=True):\n",
    "            if G_source.has_edge(n1,n2) :\n",
    "                matching_graph.add_edge(n1,n2,weight=1)\n",
    "        #graphs = list(nx.connected_component_subgraphs(matching_graph))\n",
    "        graphs = [matching_graph.subgraph(c) for c in nx.connected_components(matching_graph)]\n",
    "        mcs_length = 0\n",
    "        #mcs_graph = nx.Graph()\n",
    "        mcs_graph = nx.MultiDiGraph()\n",
    "        for i, graph in enumerate(graphs):\n",
    "            if len(graph.nodes()) > mcs_length:\n",
    "                mcs_length = len(graph.nodes())\n",
    "                mcs_graph = graph\n",
    "        return mcs_graph\n",
    "\n",
    "    def getMCS2(self, g1, g2):\n",
    "        matching_graph=nx.Graph()\n",
    "        #matching_graph=nx.MultiDiGraph()\n",
    "        for n1,n2 in g2.edges():\n",
    "            if g1.has_edge(n1, n2):\n",
    "                matching_graph.add_edge(n1, n2)\n",
    "\n",
    "        components = nx.connected_components(matching_graph)\n",
    "        largest_component = max(components, key=len)\n",
    "        #print(type(largest_component))\n",
    "        #return nx.induced_subgraph(matching_graph, largest_component)\n",
    "        return nx.induced_subgraph(g1, largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('scene', 'filter_size', 0), ('scene', 'filter_size', 1), ('filter_size', 'filter_color', 0), ('filter_color', 'count', 0), ('count', 'scene', 0)]\n"
     ]
    }
   ],
   "source": [
    "obj_graph_traversal = GraphTraversal()\n",
    "SourceSentences = \"scene filter_size filter_color count scene filter_size filter_material count less_than . \"\n",
    "SourceGraph = obj_graph_traversal.createGraph(SourceSentences)\n",
    "\n",
    "TestSentence_1 = \"scene filter_size filter_color filter_material filter_shape count scene filter_size filter_color filter_material filter_shape count greater_than . \"    #This DOES NOT Work\n",
    "TestGraph = obj_graph_traversal.createGraph(TestSentence_1)\n",
    "\n",
    "res = obj_graph_traversal.getMCS2(SourceGraph, TestGraph)\n",
    "\n",
    "print(res.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_program(SourceSentences, TestSentence_1):\n",
    "    obj_graph_traversal = GraphTraversal()\n",
    "    SourceGraph = obj_graph_traversal.createGraph(SourceSentences)\n",
    "    TestGraph = obj_graph_traversal.createGraph(TestSentence_1)\n",
    "    res = obj_graph_traversal.getMCS2(SourceGraph, TestGraph)\n",
    "    #print(res.edges)\n",
    "    return res.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_edges(SourceSentences):\n",
    "    obj_graph_traversal = GraphTraversal()\n",
    "    SourceGraph = obj_graph_traversal.createGraph(SourceSentences)\n",
    "    #TestGraph = obj_graph_traversal.createGraph(TestSentence_1)\n",
    "    #res = obj_graph_traversal.getMCS2(SourceGraph, TestGraph)\n",
    "    #print(res.edges)\n",
    "    return SourceGraph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def import_question_json():\n",
    "    with open('InputData/questions.json') as json_file:\n",
    "        data_question = json.load(json_file)\n",
    "    \n",
    "    with open('OutputData/questions.json','w') as f:\n",
    "        data_question_json = data_question['questions']\n",
    "        json.dump(data_question_json,f)\n",
    "    return data_question\n",
    "\n",
    "#import_question_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_scene_json():\n",
    "    with open('InputData/scenes.json') as json_file:\n",
    "        data_scene = json.load(json_file)\n",
    "    with open('OutputData/scenes.json','w') as f:\n",
    "        data_scene_json = data_scene['scenes']\n",
    "        json.dump(data_scene_json,f) \n",
    "    return data_scene\n",
    "\n",
    "#import_scene_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt():\n",
    "    program_list = []\n",
    "    question_list = []\n",
    "    answer_list = []\n",
    "    data_question = import_question_json()\n",
    "    for term in data_question['questions']: # for all example\n",
    "        for key,value in term.items(): # for all attribute of an example\n",
    "            if key == 'answer':\n",
    "                answer_list.append(value)\n",
    "                answer_list.append('\\n')\n",
    "            if key == 'question':\n",
    "                question_list.append(value)\n",
    "                question_list.append('\\n')\n",
    "            if key == 'program': \n",
    "                for func_dic in value:\n",
    "                    for key_, value_ in func_dic.items():\n",
    "                        if key_ == 'function':\n",
    "                            val = value_.lstrip('\\\"')+' '\n",
    "                            program_list.append(val)\n",
    "                program_list.append('. \\n')\n",
    "            else:\n",
    "                pass\n",
    "    with open(\"OutputData/answers.txt\", \"w+\") as plfile:\n",
    "        plfile.writelines(answer_list)\n",
    "    plfile.close()       \n",
    "    with open(\"OutputData/questions.txt\", \"w+\") as plfile:\n",
    "        plfile.writelines(question_list)\n",
    "    plfile.close()        \n",
    "    with open(\"OutputData/programs.txt\", \"w+\") as plfile:\n",
    "        plfile.writelines(program_list)\n",
    "    plfile.close()\n",
    "\n",
    "#generate_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "def main(x_list):\n",
    "    sub_programs_dict = []\n",
    "    sub_programs_str = ''\n",
    "    try:\n",
    "        os.mkdir('OutputData/program/')\n",
    "    except:\n",
    "        pass\n",
    "    with open('OutputData/programs.txt') as f1:\n",
    "        programs = f1.readlines()\n",
    "        program_list = []\n",
    "        for image_index in x_list:\n",
    "            program = programs[image_index]\n",
    "            program_list.append(program)\n",
    "        with open('OutputData/program/'+str(len(x_list))+'_program.pl', \"w\") as plfile:\n",
    "            print(\"{}\".format(program_list), file=plfile)\n",
    "        plfile.close()\n",
    "    f1.close()\n",
    "    #print(program_list)\n",
    "    res = {}\n",
    "    for pair_programs in permutations(program_list,2):\n",
    "        (i,j) = pair_programs\n",
    "        try:\n",
    "            sub_program = two_program(i,j)\n",
    "            sub_program = str(sub_program)\n",
    "            num = sub_program.split(',')\n",
    "            if len(num) > 3:\n",
    "                if sub_program not in res.keys():\n",
    "                    res[sub_program] = 0\n",
    "                    sub_programs_dict.append(sub_program)\n",
    "                    sub_programs_str += sub_program+'\\n'\n",
    "                else:\n",
    "                    res[sub_program] += 1\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "    #sorted_res = sorted(res.keys(), key = lambda kv:(kv[1]),reverse=True)\n",
    "    sorted_res = sorted(res.items(), key = lambda kv:(kv[1]),reverse=True)\n",
    "    with open('OutputData/'+'sub_programs.txt','w') as f:\n",
    "        for line in sorted_res:\n",
    "            #print(line[0])\n",
    "            #print(type(line[0]))\n",
    "            f.writelines(str(line[0]))\n",
    "            f.writelines('\\n')\n",
    "    f.close()\n",
    "\n",
    "sub_pro_list = main(range(688,700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_map(x_list):\n",
    "    sub_programs_str = ''\n",
    "    sub_programs_list = []\n",
    "    try:\n",
    "        os.mkdir('OutputData/program/')\n",
    "    except:\n",
    "        pass\n",
    "    with open('OutputData/programs.txt') as f1:\n",
    "        programs = f1.readlines()\n",
    "        program_list = []\n",
    "        for image_index in x_list:\n",
    "            program = programs[image_index]\n",
    "            program_list.append(program)\n",
    "        with open('OutputData/program/'+str(len(x_list))+'_program.pl', \"w\") as plfile:\n",
    "            print(\"{}\".format(program_list), file=plfile)\n",
    "        plfile.close()\n",
    "    f1.close()\n",
    "    #print(program_list)\n",
    "    for program in program_list:\n",
    "        try:\n",
    "            #print(program)\n",
    "            res = []\n",
    "            edges = double_edges(program)\n",
    "            for i,j in edges.items(): # i是边的信息,j是边的权\n",
    "                if i[2] >= 1: #边是重边\n",
    "                    double_edge = i[:2] # 重边，元组\n",
    "                    res.append(double_edge)\n",
    "                    res = list(set(res))\n",
    "                else:\n",
    "                    pass\n",
    "            sub_programs_list.append(str(res))\n",
    "            sub_programs_list.append('\\n')\n",
    "            sub_programs_str += str(res)+'\\n'\n",
    "        except:\n",
    "            pass\n",
    "    with open('OutputData/'+'edges.txt','w') as f:\n",
    "        print(\"{}\".format(sub_programs_str), file=f)\n",
    "    f.close()\n",
    "    return sub_programs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"[('unique', 'relate')]\", 22),\n",
       " (\"[('filter_size', 'filter_color')]\", 11),\n",
       " (\"[('filter_shape', 'unique')]\", 11),\n",
       " (\"[('scene', 'filter_color')]\", 9),\n",
       " (\"[('filter_color', 'filter_material')]\", 8),\n",
       " (\"[('scene', 'filter_size')]\", 7),\n",
       " (\"[('filter_material', 'filter_shape')]\", 7),\n",
       " (\"[('unique', 'query_shape')]\", 5),\n",
       " (\"[('filter_color', 'filter_shape')]\", 5),\n",
       " (\"[('filter_shape', 'count')]\", 4),\n",
       " (\"[('filter_size', 'filter_material')]\", 3),\n",
       " (\"[('unique', 'query_material')]\", 3),\n",
       " (\"[('filter_material', 'unique')]\", 2),\n",
       " (\"[('unique', 'query_color')]\", 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_map = main_map(range(60,700))\n",
    "res = {}\n",
    "for item in edges_map:\n",
    "    graph = nx.Graph()\n",
    "    num = item.split(',')\n",
    "    if len(num) == 2:\n",
    "        edge_nodes = item.replace(' ','').replace('[','').replace(']','').replace('(','').replace(')','').split(',')\n",
    "        for i in range(len(edge_nodes)//2):\n",
    "            graph.add_edges_from([(edge_nodes[2*i],edge_nodes[2*i+1])])\n",
    "        try:\n",
    "            nx.is_connected(graph)\n",
    "            #print(item)        \n",
    "            if item not in res.keys():   \n",
    "                res[item] = 0\n",
    "            else:\n",
    "                res[item] += 1\n",
    "        except:\n",
    "            pass\n",
    "top3 = sorted(res.items(), key = lambda kv:(kv[1]),reverse=True)[:100]\n",
    "top3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bad96d689ab5d20bfad05dab442cd57979884b6d4a36a886dbd8508595f0f5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
